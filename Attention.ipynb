{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "    \"\"\"\n",
    "    Computes scaled dot-product attention.\n",
    "    \n",
    "    Args:\n",
    "        query: Tensor of shape (batch_size, seq_len_q, d_k)\n",
    "        key: Tensor of shape (batch_size, seq_len_k, d_k)\n",
    "        value: Tensor of shape (batch_size, seq_len_v, d_v)\n",
    "        mask: Tensor of shape (batch_size, 1, seq_len_k) or (batch_size, seq_len_q, seq_len_k)\n",
    "\n",
    "    Returns:\n",
    "        attention_output: Tensor of shape (batch_size, seq_len_q, d_v)\n",
    "        attention_weights: Tensor of shape (batch_size, seq_len_q, seq_len_k)\n",
    "    \"\"\"\n",
    "    # Compute scores (batch_size, seq_len_q, seq_len_k)\n",
    "    d_k = query.size(-1) \n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / torch.sqrt(torch.tensor(d_k, dtype=torch.float32))\n",
    "\n",
    "    # Apply mask (if provided)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "    # Compute attention weights\n",
    "    attention_weights = F.softmax(scores, dim=-1)  # Normalize over seq_len_k\n",
    "\n",
    "    # Compute weighted sum of values\n",
    "    attention_output = torch.matmul(attention_weights, value)  # (batch_size, seq_len_q, d_v)\n",
    "\n",
    "    return attention_output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.4433, 0.6196, 0.4616,  ..., 0.7070, 0.6236, 0.3755],\n",
      "         [0.4315, 0.6178, 0.4547,  ..., 0.6820, 0.6223, 0.3787],\n",
      "         [0.4412, 0.6139, 0.4564,  ..., 0.7093, 0.6219, 0.3751],\n",
      "         [0.4459, 0.6204, 0.4533,  ..., 0.6982, 0.6300, 0.3748],\n",
      "         [0.4320, 0.6125, 0.4729,  ..., 0.7098, 0.6106, 0.3825]],\n",
      "\n",
      "        [[0.4680, 0.4281, 0.5978,  ..., 0.2877, 0.4766, 0.3701],\n",
      "         [0.4713, 0.4420, 0.5896,  ..., 0.2842, 0.4769, 0.3599],\n",
      "         [0.4525, 0.4220, 0.6075,  ..., 0.2948, 0.4650, 0.3747],\n",
      "         [0.4465, 0.4084, 0.6245,  ..., 0.2980, 0.4618, 0.3819],\n",
      "         [0.4430, 0.4244, 0.6148,  ..., 0.2979, 0.4555, 0.3687]],\n",
      "\n",
      "        [[0.5673, 0.5779, 0.6215,  ..., 0.6010, 0.6999, 0.5187],\n",
      "         [0.5501, 0.5612, 0.5859,  ..., 0.6188, 0.7274, 0.5206],\n",
      "         [0.5861, 0.5580, 0.6105,  ..., 0.6236, 0.7126, 0.5222],\n",
      "         [0.5401, 0.5768, 0.6143,  ..., 0.5989, 0.7181, 0.5197],\n",
      "         [0.5711, 0.5860, 0.6324,  ..., 0.5944, 0.6856, 0.5192]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.4258, 0.4477, 0.3552,  ..., 0.7394, 0.6621, 0.4349],\n",
      "         [0.4249, 0.4614, 0.3720,  ..., 0.7095, 0.6649, 0.4293],\n",
      "         [0.4244, 0.4560, 0.3643,  ..., 0.7193, 0.6555, 0.4318],\n",
      "         [0.4258, 0.4597, 0.3301,  ..., 0.7477, 0.6554, 0.4481],\n",
      "         [0.4294, 0.4501, 0.3416,  ..., 0.7447, 0.6536, 0.4445]],\n",
      "\n",
      "        [[0.5778, 0.4726, 0.5259,  ..., 0.5328, 0.2434, 0.4481],\n",
      "         [0.5824, 0.4892, 0.5284,  ..., 0.5652, 0.2607, 0.4621],\n",
      "         [0.5721, 0.4709, 0.5240,  ..., 0.5254, 0.2362, 0.4417],\n",
      "         [0.5658, 0.4843, 0.5362,  ..., 0.5537, 0.2473, 0.4765],\n",
      "         [0.5663, 0.4787, 0.5304,  ..., 0.5401, 0.2402, 0.4596]],\n",
      "\n",
      "        [[0.4974, 0.3564, 0.5740,  ..., 0.5037, 0.3837, 0.3651],\n",
      "         [0.4875, 0.3407, 0.5746,  ..., 0.5079, 0.3889, 0.3596],\n",
      "         [0.4938, 0.3669, 0.5880,  ..., 0.5154, 0.3711, 0.3713],\n",
      "         [0.4921, 0.3654, 0.5901,  ..., 0.5213, 0.3714, 0.3739],\n",
      "         [0.4914, 0.3552, 0.5725,  ..., 0.5035, 0.3854, 0.3604]]]), tensor([[[0.2076, 0.2017, 0.1666, 0.2454, 0.1787],\n",
      "         [0.1618, 0.2263, 0.1374, 0.2549, 0.2196],\n",
      "         [0.2178, 0.1793, 0.1680, 0.2423, 0.1925],\n",
      "         [0.1972, 0.2023, 0.1638, 0.2382, 0.1985],\n",
      "         [0.1938, 0.1920, 0.1609, 0.2646, 0.1887]],\n",
      "\n",
      "        [[0.2373, 0.1676, 0.2183, 0.1896, 0.1871],\n",
      "         [0.2532, 0.1739, 0.1944, 0.1882, 0.1903],\n",
      "         [0.2251, 0.1689, 0.2221, 0.1667, 0.2173],\n",
      "         [0.1988, 0.1790, 0.2378, 0.1742, 0.2102],\n",
      "         [0.2116, 0.1974, 0.2197, 0.1690, 0.2023]],\n",
      "\n",
      "        [[0.2100, 0.1996, 0.2183, 0.2019, 0.1702],\n",
      "         [0.1941, 0.1926, 0.1852, 0.2346, 0.1936],\n",
      "         [0.1811, 0.2288, 0.2065, 0.2172, 0.1665],\n",
      "         [0.2362, 0.1838, 0.1944, 0.2148, 0.1708],\n",
      "         [0.2123, 0.1911, 0.2343, 0.2033, 0.1590]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2263, 0.1725, 0.2221, 0.1877, 0.1914],\n",
      "         [0.2179, 0.2140, 0.1933, 0.1900, 0.1848],\n",
      "         [0.2293, 0.2067, 0.2122, 0.1698, 0.1821],\n",
      "         [0.2124, 0.1654, 0.2439, 0.1642, 0.2141],\n",
      "         [0.2222, 0.1721, 0.2442, 0.1682, 0.1934]],\n",
      "\n",
      "        [[0.2192, 0.2254, 0.2057, 0.1772, 0.1725],\n",
      "         [0.2183, 0.2437, 0.1649, 0.1790, 0.1942],\n",
      "         [0.2066, 0.2148, 0.2258, 0.1866, 0.1662],\n",
      "         [0.2072, 0.2699, 0.1807, 0.1678, 0.1744],\n",
      "         [0.2020, 0.2431, 0.2060, 0.1799, 0.1690]],\n",
      "\n",
      "        [[0.2207, 0.2310, 0.1913, 0.1629, 0.1942],\n",
      "         [0.2281, 0.2499, 0.1716, 0.1584, 0.1920],\n",
      "         [0.2181, 0.2310, 0.1891, 0.1821, 0.1797],\n",
      "         [0.2210, 0.2261, 0.1808, 0.1882, 0.1840],\n",
      "         [0.2081, 0.2475, 0.1884, 0.1681, 0.1878]]]))\n"
     ]
    }
   ],
   "source": [
    "input_seq_length = 5  # Maximum length of the input sequence\n",
    "d_k = 64  # Dimensionality of the linearly projected queries and keys\n",
    "d_v = 64  # Dimensionality of the linearly projected values\n",
    "batch_size = 64  # Batch size from the training process\n",
    " \n",
    "queries = torch.rand((batch_size, input_seq_length, d_k))\n",
    "keys = torch.rand((batch_size, input_seq_length, d_k))\n",
    "values = torch.rand((batch_size, input_seq_length, d_v))\n",
    " \n",
    "print(scaled_dot_product_attention(queries, keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[6.3756e-01, 9.0932e-01, 7.0029e-01,  ..., 9.5509e-01,\n",
       "          6.1598e-01, 1.6296e-01],\n",
       "         [6.5664e-01, 1.2814e-01, 6.8085e-01,  ..., 4.1152e-01,\n",
       "          6.7366e-01, 6.2232e-01],\n",
       "         [9.2248e-01, 4.1807e-01, 9.1756e-01,  ..., 2.8463e-01,\n",
       "          1.6877e-01, 9.0261e-01],\n",
       "         [2.2053e-01, 3.3198e-01, 4.3760e-01,  ..., 6.3471e-01,\n",
       "          3.5757e-01, 7.4478e-01],\n",
       "         [7.3801e-01, 6.1371e-01, 1.5627e-02,  ..., 9.9245e-01,\n",
       "          7.0801e-01, 1.7650e-01]],\n",
       "\n",
       "        [[6.5800e-01, 6.7176e-01, 2.5619e-01,  ..., 7.4651e-01,\n",
       "          6.8219e-01, 1.8525e-01],\n",
       "         [2.9137e-01, 3.1204e-01, 6.5756e-01,  ..., 8.5335e-01,\n",
       "          9.5485e-01, 1.8461e-01],\n",
       "         [6.1591e-01, 4.8785e-01, 3.4270e-01,  ..., 7.7645e-01,\n",
       "          5.2495e-01, 7.0066e-01],\n",
       "         [3.8391e-01, 6.0739e-01, 4.7553e-01,  ..., 7.3965e-01,\n",
       "          6.7372e-01, 1.7814e-01],\n",
       "         [6.9567e-01, 6.3398e-02, 2.3861e-01,  ..., 9.9667e-01,\n",
       "          1.8843e-01, 8.2774e-01]],\n",
       "\n",
       "        [[3.1479e-01, 6.2137e-02, 3.0361e-01,  ..., 5.3729e-01,\n",
       "          3.9276e-01, 2.1517e-01],\n",
       "         [6.2126e-04, 6.4412e-01, 1.8910e-01,  ..., 5.7404e-01,\n",
       "          8.2127e-01, 5.7018e-01],\n",
       "         [2.5951e-01, 6.7262e-01, 5.2717e-01,  ..., 3.8906e-02,\n",
       "          8.4088e-01, 4.5015e-01],\n",
       "         [7.7651e-01, 6.9193e-01, 5.6242e-01,  ..., 8.0352e-01,\n",
       "          3.2477e-01, 6.2955e-01],\n",
       "         [6.1235e-01, 5.3016e-01, 8.2009e-01,  ..., 4.8546e-01,\n",
       "          7.9339e-01, 2.5709e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[7.5440e-01, 7.7919e-01, 6.6860e-01,  ..., 5.9677e-01,\n",
       "          9.2373e-01, 7.0957e-01],\n",
       "         [5.6527e-01, 3.7198e-01, 2.3242e-01,  ..., 3.1750e-01,\n",
       "          8.5222e-01, 2.3316e-01],\n",
       "         [3.1817e-01, 6.3316e-01, 6.7255e-01,  ..., 3.4162e-01,\n",
       "          6.3370e-01, 6.1973e-01],\n",
       "         [4.8102e-01, 5.9803e-01, 8.8244e-01,  ..., 5.0538e-01,\n",
       "          4.0635e-01, 9.0893e-01],\n",
       "         [4.1850e-01, 1.5216e-01, 4.1713e-01,  ..., 7.3099e-01,\n",
       "          8.2094e-01, 2.2649e-01]],\n",
       "\n",
       "        [[6.9781e-01, 4.3622e-01, 8.8902e-02,  ..., 3.3590e-01,\n",
       "          7.9899e-01, 6.0263e-01],\n",
       "         [4.4712e-01, 2.5521e-01, 8.1523e-01,  ..., 2.1245e-01,\n",
       "          7.7488e-01, 1.6430e-01],\n",
       "         [4.8315e-01, 9.7726e-01, 1.4188e-01,  ..., 4.0781e-01,\n",
       "          1.8382e-01, 8.3846e-03],\n",
       "         [7.1631e-01, 8.1158e-01, 7.6583e-01,  ..., 1.2354e-01,\n",
       "          9.8490e-01, 5.8557e-01],\n",
       "         [6.6028e-01, 6.5241e-01, 7.9910e-01,  ..., 9.4602e-01,\n",
       "          9.8361e-01, 7.5180e-01]],\n",
       "\n",
       "        [[2.4677e-01, 2.8398e-01, 5.1015e-01,  ..., 3.6057e-01,\n",
       "          8.1797e-01, 4.5454e-01],\n",
       "         [6.6899e-01, 6.1417e-01, 3.2278e-01,  ..., 9.1943e-01,\n",
       "          9.7940e-01, 2.8609e-01],\n",
       "         [1.2482e-01, 4.4768e-01, 6.7047e-01,  ..., 8.8826e-01,\n",
       "          5.0458e-01, 4.0090e-01],\n",
       "         [7.1239e-03, 8.1666e-01, 8.3722e-01,  ..., 6.8661e-01,\n",
       "          3.2445e-01, 7.5096e-03],\n",
       "         [8.9297e-01, 2.3168e-01, 8.7900e-01,  ..., 5.2945e-01,\n",
       "          8.0171e-01, 2.8324e-01]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
